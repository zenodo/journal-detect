{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0ef65a2",
   "metadata": {},
   "source": [
    "# Zenodo Journal Runner Detection - Exploratory Data Analysis\n",
    "\n",
    "This notebook performs an explainable exploratory analysis of Zenodo records to identify users who appear to be running journals on the platform.\n",
    "\n",
    "## Overview\n",
    "- **Data Source**: 500,000+ JSON records from Zenodo (2025)\n",
    "- **Goal**: Identify users with journal-running behavior patterns\n",
    "- **Approach**: Feature engineering based on explainable heuristics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45f30e2",
   "metadata": {},
   "source": [
    "## 1. Configuration and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade21d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams\n",
    "\n",
    "# Statistics\n",
    "from scipy import stats\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "rcParams['figure.figsize'] = (12, 8)\n",
    "rcParams['font.size'] = 10\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs('figures', exist_ok=True)\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "# Configuration parameters\n",
    "CONFIG = {\n",
    "    'json_dir': 'records-json-2025',\n",
    "    'spam_file': 'records-deleted-2025.csv',\n",
    "    'sample_size': None,  # Set to number for sampling, None for full dataset\n",
    "    'chunk_size': 1000,   # Process files in chunks\n",
    "    'min_records_threshold': 20,\n",
    "    'external_doi_consistency_threshold': 0.7,  # 70% of external DOIs use same prefix\n",
    "    'max_external_prefixes': 3,  # Max unique external DOI prefixes\n",
    "    'min_upload_regularity': 0.1,  # Much more mild upload regularity threshold (was 0.3)\n",
    "    'max_spam_ratio': 0.1,  # Max 10% spam records\n",
    "    # Safe communities that indicate independent users (not journal runners)\n",
    "    'safe_communities': ['eu', 'biosyslit'],  # EU Open Research Repository and Biodiversity Literature Repository\n",
    "    'repetitive_author_threshold': 0.3,  # If 30% of entries have no author intersection, likely journal runner\n",
    "    'min_author_intersection_ratio': 0.2  # Minimum ratio of entries that share at least one author\n",
    "}\n",
    "\n",
    "print(f\"Configuration loaded. Processing directory: {CONFIG['json_dir']}\")\n",
    "print(f\"Spam records file: {CONFIG['spam_file']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b00d4b",
   "metadata": {},
   "source": [
    "## 2. Data Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e0ab77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_spam_records(filepath):\n",
    "    \"\"\"Load spam records CSV file.\"\"\"\n",
    "    print(f\"Loading spam records from {filepath}...\")\n",
    "    spam_df = pd.read_csv(filepath)\n",
    "    print(f\"Loaded {len(spam_df)} spam records\")\n",
    "    return spam_df\n",
    "\n",
    "def extract_record_features(record):\n",
    "    \"\"\"Extract relevant features from a single JSON record.\"\"\"\n",
    "    try:\n",
    "        # Basic record info\n",
    "        record_id = record.get('id')\n",
    "        created = record.get('created')\n",
    "        \n",
    "        # User info\n",
    "        user_id = record.get('parent', {}).get('access', {}).get('owned_by', {}).get('user')\n",
    "        \n",
    "        # DOI info\n",
    "        doi = record.get('pids', {}).get('doi', {}).get('identifier', '')\n",
    "        is_zenodo_doi = doi.startswith('10.5281/zenodo.') if doi else False\n",
    "        \n",
    "        # External DOI prefix (for consistency analysis)\n",
    "        external_doi_prefix = None\n",
    "        if doi and not is_zenodo_doi and '/' in doi:\n",
    "            external_doi_prefix = doi.split('/')[0]\n",
    "        \n",
    "        # Journal info\n",
    "        journal_title = None\n",
    "        if 'custom_fields' in record and \\\n",
    "           'journal:journal' in record['custom_fields']:\n",
    "            journal_title = record['custom_fields']['journal:journal'].get('title')\n",
    "        \n",
    "        # Author analysis - extract all author names from the full author list\n",
    "        creators = record.get('metadata', {}).get('creators', [])\n",
    "        n_authors = len(creators) if creators else 0\n",
    "        \n",
    "        # Extract all author names for intersection analysis\n",
    "        author_names = []\n",
    "        if creators:\n",
    "            for creator in creators:\n",
    "                if 'person_or_org' in creator and 'name' in creator['person_or_org']:\n",
    "                    author_names.append(creator['person_or_org']['name'])\n",
    "        \n",
    "        # Title analysis\n",
    "        title = record.get('metadata', {}).get('title', '')\n",
    "        \n",
    "        # Community info - check both main record and parent, extract slug\n",
    "        communities = []\n",
    "        community_slugs = []\n",
    "        if 'communities' in record and 'ids' in record['communities']:\n",
    "            communities = record['communities']['ids']\n",
    "        elif 'parent' in record and 'communities' in record['parent'] and 'ids' in record['parent']['communities']:\n",
    "            communities = record['parent']['communities']['ids']\n",
    "        \n",
    "        # Extract community slugs\n",
    "        if 'parent' in record and 'communities' in record['parent'] and 'entries' in record['parent']['communities']:\n",
    "            for entry in record['parent']['communities']['entries']:\n",
    "                if 'slug' in entry:\n",
    "                    community_slugs.append(entry['slug'])\n",
    "        \n",
    "        # File info\n",
    "        file_count = record.get('files', {}).get('count', 0)\n",
    "        \n",
    "        return {\n",
    "            'record_id': record_id,\n",
    "            'user_id': user_id,\n",
    "            'created': created,\n",
    "            'doi': doi,\n",
    "            'is_zenodo_doi': is_zenodo_doi,\n",
    "            'external_doi_prefix': external_doi_prefix,\n",
    "            'journal_title': journal_title,\n",
    "            'n_authors': n_authors,\n",
    "            'author_names': author_names,\n",
    "            'title': title,\n",
    "            'communities': communities,\n",
    "            'community_slugs': community_slugs,\n",
    "            'file_count': file_count\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing record {record.get('id', 'unknown')}: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_records_generator(json_dir, sample_size=None):\n",
    "    \"\"\"Generator function to load records in chunks for memory efficiency.\"\"\"\n",
    "    json_files = glob.glob(os.path.join(json_dir, '*.json'))\n",
    "    \n",
    "    if sample_size:\n",
    "        json_files = json_files[:sample_size]\n",
    "    \n",
    "    print(f\"Processing {len(json_files)} JSON files...\")\n",
    "    \n",
    "    for filepath in tqdm(json_files, desc=\"Loading records\"):\n",
    "        try:\n",
    "            with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                record = json.load(f)\n",
    "                features = extract_record_features(record)\n",
    "                if features:\n",
    "                    yield features\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {filepath}: {e}\")\n",
    "            continue\n",
    "\n",
    "def load_records_to_dataframe(json_dir, sample_size=None):\n",
    "    \"\"\"Load all records into a pandas DataFrame.\"\"\"\n",
    "    records = list(load_records_generator(json_dir, sample_size))\n",
    "    df = pd.DataFrame(records)\n",
    "    \n",
    "    # Convert created to datetime\n",
    "    try:\n",
    "        df['created'] = pd.to_datetime(df['created'], format='mixed', errors='coerce')\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Some datetime parsing failed: {e}\")\n",
    "        # Fallback to more permissive parsing\n",
    "        df['created'] = pd.to_datetime(df['created'], errors='coerce')\n",
    "    \n",
    "    # Remove rows where datetime parsing failed\n",
    "    original_count = len(df)\n",
    "    df = df.dropna(subset=['created'])\n",
    "    if len(df) < original_count:\n",
    "        print(f\"Warning: Dropped {original_count - len(df)} records with invalid datetime\")\n",
    "    \n",
    "    print(f\"Loaded {len(df)} records from {df['user_id'].nunique()} unique users\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a7a780",
   "metadata": {},
   "source": [
    "## 3. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a985787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spam records\n",
    "spam_df = load_spam_records(CONFIG['spam_file'])\n",
    "spam_record_ids = set(spam_df['record_id'].astype(str))\n",
    "\n",
    "# Load main records\n",
    "records_df = load_records_to_dataframe(CONFIG['json_dir'], CONFIG['sample_size'])\n",
    "\n",
    "# Add spam flag\n",
    "records_df['is_spam_record'] = records_df['record_id'].astype(str).isin(spam_record_ids)\n",
    "\n",
    "print(f\"\\nData Summary:\")\n",
    "print(f\"Total records: {len(records_df):,}\")\n",
    "print(f\"Unique users: {records_df['user_id'].nunique():,}\")\n",
    "print(f\"Spam records: {records_df['is_spam_record'].sum():,}\")\n",
    "print(f\"Date range: {records_df['created'].min()} to {records_df['created'].max()}\")\n",
    "\n",
    "# Save records to parquet for future use\n",
    "records_df.to_parquet('data/records.parquet', index=False)\n",
    "print(\"\\nRecords saved to data/records.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e803f30",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b742c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_burstiness(upload_times):\n",
    "    \"\"\"\n",
    "    Calculate burstiness using coefficient of variation of inter-upload times.\n",
    "    \n",
    "    Burstiness measures how irregular or clustered the upload timing patterns are.\n",
    "    A high burstiness value indicates uploads happen in concentrated bursts with \n",
    "    long gaps between them (typical of journal runners who upload many papers at once).\n",
    "    A low burstiness value indicates regular, evenly-spaced uploads (typical of \n",
    "    normal academic users who upload papers as they complete them).\n",
    "    \n",
    "    The coefficient of variation (std/mean) of time intervals between uploads \n",
    "    captures this pattern - higher values mean more bursty behavior.\n",
    "    \"\"\"\n",
    "    if len(upload_times) < 2:\n",
    "        return 0.0\n",
    "    \n",
    "    # Sort times and calculate intervals\n",
    "    sorted_times = sorted(upload_times)\n",
    "    intervals = np.diff([t.timestamp() for t in sorted_times])\n",
    "    \n",
    "    if len(intervals) == 0 or np.std(intervals) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    # Coefficient of variation\n",
    "    cv = np.std(intervals) / np.mean(intervals)\n",
    "    return cv\n",
    "\n",
    "def extract_user_features(user_records):\n",
    "    \"\"\"Extract features for a single user from their records.\"\"\"\n",
    "    user_id = user_records['user_id'].iloc[0]\n",
    "    \n",
    "    # Basic counts\n",
    "    n_records = len(user_records)\n",
    "    \n",
    "    # External DOI consistency (more important than Zenodo ratio)\n",
    "    external_dois = user_records[~user_records['is_zenodo_doi']]['external_doi_prefix'].dropna()\n",
    "    if len(external_dois) > 0:\n",
    "        unique_prefixes = external_dois.nunique()\n",
    "        most_common_prefix = external_dois.mode().iloc[0] if len(external_dois.mode()) > 0 else None\n",
    "        external_doi_consistency = (external_dois == most_common_prefix).mean() if most_common_prefix else 0.0\n",
    "    else:\n",
    "        unique_prefixes = 0\n",
    "        external_doi_consistency = 0.0\n",
    "    \n",
    "    # Author analysis - check for repetitive authors (this is the key feature for journal runners)\n",
    "    all_author_lists = user_records['author_names'].dropna().tolist()\n",
    "    no_repetitive_author_score = 0.0\n",
    "    author_intersection_ratio = 0.0\n",
    "    \n",
    "    if len(all_author_lists) >= 2:\n",
    "        # Calculate how many pairs of entries have no author intersection\n",
    "        no_intersection_count = 0\n",
    "        total_pairs = 0\n",
    "        \n",
    "        for i in range(len(all_author_lists)):\n",
    "            for j in range(i+1, len(all_author_lists)):\n",
    "                total_pairs += 1\n",
    "                set1 = set(all_author_lists[i])\n",
    "                set2 = set(all_author_lists[j])\n",
    "                if len(set1.intersection(set2)) == 0:\n",
    "                    no_intersection_count += 1\n",
    "        \n",
    "        if total_pairs > 0:\n",
    "            no_repetitive_author_score = no_intersection_count / total_pairs\n",
    "            author_intersection_ratio = 1.0 - no_repetitive_author_score\n",
    "    \n",
    "    # Journal title consistency\n",
    "    journal_titles = user_records['journal_title'].dropna()\n",
    "    distinct_journal_title_cnt = journal_titles.nunique()\n",
    "    \n",
    "    # Community analysis - check for safe communities\n",
    "    all_community_slugs = []\n",
    "    for community_slugs in user_records['community_slugs'].dropna():\n",
    "        if isinstance(community_slugs, list):\n",
    "            all_community_slugs.extend(community_slugs)\n",
    "    \n",
    "    # Check if user has any safe communities (indicates independent user)\n",
    "    has_safe_community = any(slug in CONFIG['safe_communities'] for slug in all_community_slugs)\n",
    "    \n",
    "    # Community dedication ratio (kept as feature but no threshold)\n",
    "    if all_community_slugs:\n",
    "        community_counts = pd.Series(all_community_slugs).value_counts()\n",
    "        most_common_community = community_counts.index[0]\n",
    "        same_comm_ratio = community_counts.iloc[0] / len(all_community_slugs)\n",
    "    else:\n",
    "        same_comm_ratio = 0.0\n",
    "    \n",
    "    # Temporal analysis\n",
    "    upload_times = user_records['created'].dropna()\n",
    "    burstiness = calculate_burstiness(upload_times)\n",
    "    \n",
    "    # Upload regularity (how consistent are the intervals) - much more mild threshold\n",
    "    upload_regularity = 0.0\n",
    "    if len(upload_times) >= 3:\n",
    "        sorted_times = sorted(upload_times)\n",
    "        intervals = np.diff([t.timestamp() for t in sorted_times])\n",
    "        # Lower coefficient of variation = more regular\n",
    "        if np.mean(intervals) > 0:\n",
    "            upload_regularity = 1.0 / (1.0 + np.std(intervals) / np.mean(intervals))\n",
    "    \n",
    "    # Spam association\n",
    "    spam_record_cnt = user_records['is_spam_record'].sum()\n",
    "    spam_record_ratio = spam_record_cnt / n_records if n_records > 0 else 0.0\n",
    "    \n",
    "    return {\n",
    "        'user_id': user_id,\n",
    "        'n_records': n_records,\n",
    "        'external_doi_consistency': external_doi_consistency,\n",
    "        'unique_external_prefixes': unique_prefixes,\n",
    "        'no_repetitive_author_score': no_repetitive_author_score,\n",
    "        'author_intersection_ratio': author_intersection_ratio,\n",
    "        'distinct_journal_title_cnt': distinct_journal_title_cnt,\n",
    "        'has_safe_community': has_safe_community,\n",
    "        'same_comm_ratio': same_comm_ratio,\n",
    "        'burstiness': burstiness,\n",
    "        'upload_regularity': upload_regularity,\n",
    "        'spam_record_cnt': spam_record_cnt,\n",
    "        'spam_record_ratio': spam_record_ratio,\n",
    "        'first_upload': upload_times.min() if len(upload_times) > 0 else None,\n",
    "        'last_upload': upload_times.max() if len(upload_times) > 0 else None\n",
    "    }\n",
    "\n",
    "def create_user_features_df(records_df):\n",
    "    \"\"\"Create user-level features DataFrame.\"\"\"\n",
    "    print(\"Extracting user-level features...\")\n",
    "    \n",
    "    user_features = []\n",
    "    for user_id, user_records in tqdm(records_df.groupby('user_id'), desc=\"Processing users\"):\n",
    "        features = extract_user_features(user_records)\n",
    "        user_features.append(features)\n",
    "    \n",
    "    users_df = pd.DataFrame(user_features)\n",
    "    \n",
    "    print(f\"Created features for {len(users_df)} users\")\n",
    "    return users_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670fd76b",
   "metadata": {},
   "source": [
    "## 5. Generate User Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85fd0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create user features\n",
    "users_df = create_user_features_df(records_df)\n",
    "\n",
    "# Display feature summary\n",
    "print(\"\\nUser Features Summary:\")\n",
    "print(users_df.describe())\n",
    "\n",
    "# Save user features\n",
    "users_df.to_parquet('data/users.parquet', index=False)\n",
    "print(\"\\nUser features saved to data/users.parquet\")\n",
    "\n",
    "# Show top users by record count\n",
    "print(\"\\nTop 10 users by record count:\")\n",
    "print(users_df.nlargest(10, 'n_records')[['user_id', 'n_records', 'external_doi_consistency', 'spam_record_cnt']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a556f7e4",
   "metadata": {},
   "source": [
    "## 6. Exploratory Data Analysis - Feature Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95953b5",
   "metadata": {},
   "source": [
    "Understanding the distribution of our engineered features is crucial for identifying journal runner behavior patterns. These plots reveal how normal academic users differ from potential journal runners across key metrics like record volume, DOI consistency, and author patterns. The log scales and threshold highlighting help us identify the long tail of high-volume users who are most likely to be running journals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7f8589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create more meaningful distribution plots with better insights\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# 1. Records per user distribution with log scale and annotations\n",
    "hist, bins, _ = axes[0].hist(users_df['n_records'], bins=50, alpha=0.7, edgecolor='black', color='skyblue')\n",
    "axes[0].set_xlabel('Number of Records per User')\n",
    "axes[0].set_ylabel('Number of Users')\n",
    "axes[0].set_title('Distribution of Records per User\\n(Log Scale)')\n",
    "axes[0].set_yscale('log')\n",
    "axes[0].set_xscale('log')\n",
    "\n",
    "# Add percentile annotations\n",
    "percentiles = [50, 75, 90, 95, 99]\n",
    "for p in percentiles:\n",
    "    value = np.percentile(users_df['n_records'], p)\n",
    "    axes[0].axvline(value, color='red', linestyle='--', alpha=0.7)\n",
    "    axes[0].text(value, axes[0].get_ylim()[1]*0.8, f'{p}%', rotation=90, fontsize=8)\n",
    "\n",
    "# 2. External DOI consistency with threshold highlighting\n",
    "hist, bins, _ = axes[1].hist(users_df['external_doi_consistency'], bins=30, alpha=0.7, edgecolor='black', color='lightgreen')\n",
    "axes[1].set_xlabel('External DOI Consistency')\n",
    "axes[1].set_ylabel('Number of Users')\n",
    "axes[1].set_title('Distribution of External DOI Consistency\\n(Threshold Highlighted)')\n",
    "\n",
    "# Highlight threshold region\n",
    "threshold = CONFIG['external_doi_consistency_threshold']\n",
    "mask = users_df['external_doi_consistency'] >= threshold\n",
    "axes[1].hist(users_df.loc[mask, 'external_doi_consistency'], bins=bins, alpha=0.9, \n",
    "             color='red', edgecolor='black', label=f'â‰¥{threshold} ({mask.sum()} users)')\n",
    "axes[1].legend()\n",
    "\n",
    "# 3. Repetitive author score with interpretation\n",
    "hist, bins, _ = axes[2].hist(users_df['no_repetitive_author_score'], bins=30, alpha=0.7, edgecolor='black', color='orange')\n",
    "axes[2].set_xlabel('Repetitive Author Score')\n",
    "axes[2].set_ylabel('Number of Users')\n",
    "axes[2].set_title('Distribution of Repetitive Author Score\\n(Higher = More Journal-like)')\n",
    "\n",
    "# Add interpretation zones\n",
    "axes[2].axvspan(0, 0.2, alpha=0.2, color='green', label='Normal Users')\n",
    "axes[2].axvspan(0.2, 0.5, alpha=0.2, color='yellow', label='Suspicious')\n",
    "axes[2].axvspan(0.5, 1.0, alpha=0.2, color='red', label='Likely Journal Runner')\n",
    "axes[2].legend()\n",
    "\n",
    "# 4. Author intersection ratio (inverse of repetitive score)\n",
    "hist, bins, _ = axes[3].hist(users_df['author_intersection_ratio'], bins=30, alpha=0.7, edgecolor='black', color='purple')\n",
    "axes[3].set_xlabel('Author Intersection Ratio')\n",
    "axes[3].set_ylabel('Number of Users')\n",
    "axes[3].set_title('Distribution of Author Intersection Ratio\\n(Higher = More Collaborative)')\n",
    "\n",
    "# Add interpretation\n",
    "axes[3].axvspan(0.8, 1.0, alpha=0.2, color='green', label='High Collaboration')\n",
    "axes[3].axvspan(0.5, 0.8, alpha=0.2, color='yellow', label='Moderate Collaboration')\n",
    "axes[3].axvspan(0, 0.5, alpha=0.2, color='red', label='Low Collaboration')\n",
    "axes[3].legend()\n",
    "\n",
    "# 5. Journal title diversity with insights\n",
    "hist, bins, _ = axes[4].hist(users_df['distinct_journal_title_cnt'], bins=range(0, 21), alpha=0.7, edgecolor='black', color='brown')\n",
    "axes[4].set_xlabel('Distinct Journal Titles')\n",
    "axes[4].set_ylabel('Number of Users')\n",
    "axes[4].set_title('Distribution of Distinct Journal Titles\\n(Diversity Indicator)')\n",
    "\n",
    "# Add insights\n",
    "single_journal = (users_df['distinct_journal_title_cnt'] == 1).sum()\n",
    "multiple_journals = (users_df['distinct_journal_title_cnt'] > 1).sum()\n",
    "axes[4].text(0.7, 0.8, f'Single Journal: {single_journal}\\nMultiple: {multiple_journals}', \n",
    "             transform=axes[4].transAxes, bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8))\n",
    "\n",
    "# 6. Upload burstiness with interpretation\n",
    "hist, bins, _ = axes[5].hist(users_df['burstiness'], bins=50, alpha=0.7, edgecolor='black', color='pink')\n",
    "axes[5].set_xlabel('Upload Burstiness (CV of Intervals)')\n",
    "axes[5].set_ylabel('Number of Users')\n",
    "axes[5].set_title('Distribution of Upload Burstiness\\n(Higher = More Irregular)')\n",
    "\n",
    "# Add interpretation zones\n",
    "low_burst = users_df['burstiness'] <= 1\n",
    "high_burst = users_df['burstiness'] > 2\n",
    "axes[5].axvspan(0, 1, alpha=0.2, color='green', label=f'Regular ({low_burst.sum()} users)')\n",
    "axes[5].axvspan(2, axes[5].get_xlim()[1], alpha=0.2, color='red', label=f'Bursty ({high_burst.sum()} users)')\n",
    "axes[5].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/feature_distributions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Enhanced feature distributions saved to figures/feature_distributions.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8eb75e",
   "metadata": {},
   "source": [
    "## 7. Correlation Analysis with Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cf559b",
   "metadata": {},
   "source": [
    "Correlation analysis reveals which features work together to identify journal runners, helping us understand the complex behavioral patterns that distinguish normal academic users from those running journals. Strong correlations between features like repetitive author scores and upload burstiness suggest these are complementary signals of journal-running behavior rather than independent indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d74ec49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a more insightful correlation analysis\n",
    "numeric_features = ['n_records', 'external_doi_consistency', 'no_repetitive_author_score', \n",
    "                   'author_intersection_ratio', 'distinct_journal_title_cnt', \n",
    "                   'same_comm_ratio', 'burstiness', 'upload_regularity', 'spam_record_cnt']\n",
    "\n",
    "# Create correlation matrix\n",
    "correlation_matrix = users_df[numeric_features].corr()\n",
    "\n",
    "# Create a more informative correlation heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Create mask for upper triangle to show only lower triangle\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "\n",
    "# Plot heatmap with better styling\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='RdBu_r', center=0, \n",
    "            square=True, fmt='.2f', cbar_kws={'shrink': 0.8, 'label': 'Correlation Coefficient'},\n",
    "            linewidths=0.5, linecolor='white')\n",
    "\n",
    "plt.title('Feature Correlation Matrix\\n(Journal Runner Detection Features)', pad=20, fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/correlation_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Enhanced correlation heatmap saved to figures/correlation_heatmap.png\")\n",
    "\n",
    "# Show top correlations with interpretation\n",
    "print(\"\\nðŸ” TOP FEATURE CORRELATIONS (with interpretation):\")\n",
    "correlations = []\n",
    "for i in range(len(numeric_features)):\n",
    "    for j in range(i+1, len(numeric_features)):\n",
    "        feat1, feat2 = numeric_features[i], numeric_features[j]\n",
    "        corr = correlation_matrix.loc[feat1, feat2]\n",
    "        correlations.append((feat1, feat2, corr))\n",
    "\n",
    "correlations.sort(key=lambda x: abs(x[2]), reverse=True)\n",
    "\n",
    "# Define correlation interpretations\n",
    "interpretations = {\n",
    "    'n_records vs distinct_journal_title_cnt': 'High correlation suggests journal runners publish across many titles',\n",
    "    'n_records vs burstiness': 'More records often means more irregular upload patterns',\n",
    "    'author_intersection_ratio vs upload_regularity': 'Collaborative users tend to upload more regularly',\n",
    "    'no_repetitive_author_score vs burstiness': 'Journal runners show both repetitive authors and bursty uploads',\n",
    "    'no_repetitive_author_score vs upload_regularity': 'Repetitive authors often upload irregularly'\n",
    "}\n",
    "\n",
    "for feat1, feat2, corr in correlations[:8]:\n",
    "    key = f\"{feat1} vs {feat2}\"\n",
    "    interpretation = interpretations.get(key, \"Interesting relationship between features\")\n",
    "    print(f\"  {key}: {corr:.3f} - {interpretation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da72e2b",
   "metadata": {},
   "source": [
    "## 8. Multi-dimensional Scatter Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2d5d32",
   "metadata": {},
   "source": [
    "Multi-dimensional scatter plots allow us to visualize how different behavioral patterns interact in real users, revealing the complex combinations of features that characterize journal runners. By coloring points by additional features, we can see how high-volume users with consistent external DOIs also tend to have repetitive author patterns and irregular upload timing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65467a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a more insightful multi-dimensional scatter plot\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Records vs External DOI consistency with multiple indicators\n",
    "scatter1 = axes[0,0].scatter(users_df['n_records'], users_df['external_doi_consistency'], \n",
    "                            c=users_df['no_repetitive_author_score'], cmap='viridis', \n",
    "                            alpha=0.6, s=50)\n",
    "axes[0,0].set_xlabel('Number of Records (log scale)')\n",
    "axes[0,0].set_ylabel('External DOI Consistency')\n",
    "axes[0,0].set_title('Records vs DOI Consistency\\n(colored by repetitive author score)')\n",
    "axes[0,0].set_xscale('log')\n",
    "plt.colorbar(scatter1, ax=axes[0,0], label='Repetitive Author Score')\n",
    "\n",
    "# Add threshold lines\n",
    "axes[0,0].axhline(y=CONFIG['external_doi_consistency_threshold'], color='red', linestyle='--', \n",
    "                  alpha=0.7, label=f'DOI threshold ({CONFIG[\"external_doi_consistency_threshold\"]})')\n",
    "axes[0,0].axvline(x=CONFIG['min_records_threshold'], color='red', linestyle='--', \n",
    "                  alpha=0.7, label=f'Records threshold ({CONFIG[\"min_records_threshold\"]})')\n",
    "axes[0,0].legend()\n",
    "\n",
    "# 2. Author patterns vs upload patterns\n",
    "scatter2 = axes[0,1].scatter(users_df['no_repetitive_author_score'], users_df['burstiness'], \n",
    "                            c=users_df['n_records'], cmap='plasma', \n",
    "                            alpha=0.6, s=50)\n",
    "axes[0,1].set_xlabel('Repetitive Author Score')\n",
    "axes[0,1].set_ylabel('Upload Burstiness')\n",
    "axes[0,1].set_title('Author Patterns vs Upload Patterns\\n(colored by record count)')\n",
    "plt.colorbar(scatter2, ax=axes[0,1], label='Number of Records')\n",
    "\n",
    "# Add interpretation quadrants\n",
    "axes[0,1].axhline(y=1, color='gray', linestyle=':', alpha=0.5)\n",
    "axes[0,1].axvline(x=0.3, color='gray', linestyle=':', alpha=0.5)\n",
    "axes[0,1].text(0.1, 0.5, 'Normal\\nUsers', transform=axes[0,1].transAxes, ha='center', \n",
    "               bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgreen\", alpha=0.7))\n",
    "axes[0,1].text(0.7, 2, 'Journal\\nRunners', transform=axes[0,1].transAxes, ha='center',\n",
    "               bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"red\", alpha=0.7))\n",
    "\n",
    "# 3. Community dedication vs journal diversity\n",
    "scatter3 = axes[1,0].scatter(users_df['same_comm_ratio'], users_df['distinct_journal_title_cnt'], \n",
    "                            c=users_df['spam_record_cnt'], cmap='Reds', \n",
    "                            alpha=0.6, s=50)\n",
    "axes[1,0].set_xlabel('Community Dedication Ratio')\n",
    "axes[1,0].set_ylabel('Distinct Journal Titles')\n",
    "axes[1,0].set_title('Community Dedication vs Journal Diversity\\n(colored by spam count)')\n",
    "plt.colorbar(scatter3, ax=axes[1,0], label='Spam Record Count')\n",
    "\n",
    "# 4. Upload regularity vs author intersection\n",
    "scatter4 = axes[1,1].scatter(users_df['upload_regularity'], users_df['author_intersection_ratio'], \n",
    "                            c=users_df['external_doi_consistency'], cmap='Blues', \n",
    "                            alpha=0.6, s=50)\n",
    "axes[1,1].set_xlabel('Upload Regularity')\n",
    "axes[1,1].set_ylabel('Author Intersection Ratio')\n",
    "axes[1,1].set_title('Upload Regularity vs Author Collaboration\\n(colored by DOI consistency)')\n",
    "plt.colorbar(scatter4, ax=axes[1,1], label='External DOI Consistency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/multi_dimensional_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Multi-dimensional scatter analysis saved to figures/multi_dimensional_analysis.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2231a8d8",
   "metadata": {},
   "source": [
    "## 9. Journal Runner Candidate Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57947639",
   "metadata": {},
   "source": [
    "Applying our heuristic filters allows us to identify users who exhibit multiple journal-running behaviors simultaneously, creating a more robust detection system than relying on any single feature. This multi-criteria approach helps us distinguish between legitimate high-volume academic users and those who are likely running journals on the platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3eb84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Applying journal runner detection heuristics...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7038a8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = users_df[\n",
    "    (users_df['n_records'] >= CONFIG['min_records_threshold']) &\n",
    "    (users_df['external_doi_consistency'] >= CONFIG['external_doi_consistency_threshold']) &\n",
    "    (users_df['upload_regularity'] >= CONFIG['min_upload_regularity']) &\n",
    "    (users_df['spam_record_ratio'] <= CONFIG['max_spam_ratio']) &\n",
    "    (~users_df['has_safe_community']) &  # Exclude users with safe communities\n",
    "    (users_df['no_repetitive_author_score'] >= CONFIG['repetitive_author_threshold'])  # High repetitive author score\n",
    "].sort_values('external_doi_consistency', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17254d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nFound {len(candidates)} users meeting journal runner criteria\")\n",
    "print(f\"Out of {len(users_df)} total users with >= {CONFIG['min_records_threshold']} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be789681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display top candidates\n",
    "print(\"\\nTop 20 Journal Runner Candidates:\")\n",
    "display_columns = ['user_id', 'n_records', 'external_doi_consistency', 'no_repetitive_author_score', \n",
    "                  'author_intersection_ratio', 'upload_regularity', 'spam_record_ratio', 'burstiness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a745769d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print candidates table instead of using display\n",
    "print(candidates[display_columns].head(20).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eeb2d10",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Save candidates to CSV\n",
    "candidates.to_csv('data/journal_runner_candidates.csv', index=False)\n",
    "print(\"\\nCandidates saved to data/journal_runner_candidates.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5063e6bc",
   "metadata": {},
   "source": [
    "## 10. Enhanced Timeline Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b901c4",
   "metadata": {},
   "source": [
    "Timeline analysis reveals the temporal patterns that distinguish journal runners from normal users, showing how they tend to upload papers in concentrated bursts rather than steadily over time. These visualizations help us understand the real-world behavior of our top candidates, showing their upload frequency, DOI usage patterns, and any association with spam records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951c7134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_enhanced_user_timeline(user_id, records_df, users_df):\n",
    "    \"\"\"Create an enhanced timeline plot with multiple insights.\"\"\"\n",
    "    user_records = records_df[records_df['user_id'] == user_id].copy()\n",
    "    user_records = user_records.sort_values('created')\n",
    "    user_stats = users_df[users_df['user_id'] == user_id].iloc[0]\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10), height_ratios=[2, 1])\n",
    "    \n",
    "    # Main timeline plot\n",
    "    dates = user_records['created']\n",
    "    cumulative_count = range(1, len(dates) + 1)\n",
    "    \n",
    "    # Color points by various metrics\n",
    "    colors = []\n",
    "    for _, record in user_records.iterrows():\n",
    "        if record['is_spam_record']:\n",
    "            colors.append('red')\n",
    "        elif record['is_zenodo_doi']:\n",
    "            colors.append('blue')\n",
    "        else:\n",
    "            colors.append('green')\n",
    "    \n",
    "    scatter = ax1.scatter(dates, cumulative_count, c=colors, alpha=0.7, s=30)\n",
    "    \n",
    "    # Add trend line\n",
    "    if len(dates) > 1:\n",
    "        z = np.polyfit([d.timestamp() for d in dates], cumulative_count, 1)\n",
    "        p = np.poly1d(z)\n",
    "        ax1.plot(dates, p([d.timestamp() for d in dates]), \"r--\", alpha=0.8, label='Upload Trend')\n",
    "    \n",
    "    # Highlight spam records\n",
    "    spam_records = user_records[user_records['is_spam_record']]\n",
    "    if len(spam_records) > 0:\n",
    "        spam_indices = [list(user_records['created']).index(t) for t in spam_records['created']]\n",
    "        ax1.scatter(spam_records['created'], [i+1 for i in spam_indices], \n",
    "                   alpha=0.9, s=60, c='red', marker='x', label='Spam Records', linewidth=2)\n",
    "    \n",
    "    ax1.set_xlabel('Date')\n",
    "    ax1.set_ylabel('Cumulative Upload Count')\n",
    "    ax1.set_title(f'Enhanced Upload Timeline for User {user_id}\\n'\n",
    "                  f'Records: {user_stats[\"n_records\"]} | DOI Consistency: {user_stats[\"external_doi_consistency\"]:.2f} | '\n",
    "                  f'Repetitive Score: {user_stats[\"no_repetitive_author_score\"]:.2f}')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add color legend\n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = [Patch(facecolor='blue', label='Zenodo DOI'),\n",
    "                      Patch(facecolor='green', label='External DOI'),\n",
    "                      Patch(facecolor='red', label='Spam Record')]\n",
    "    ax1.legend(handles=legend_elements, loc='upper left')\n",
    "    \n",
    "    # Upload frequency analysis\n",
    "    if len(dates) > 1:\n",
    "        # Calculate daily upload counts\n",
    "        daily_counts = user_records.groupby(user_records['created'].dt.date).size()\n",
    "        \n",
    "        ax2.bar(daily_counts.index, daily_counts.values, alpha=0.7, color='lightblue', edgecolor='black')\n",
    "        ax2.set_xlabel('Date')\n",
    "        ax2.set_ylabel('Uploads per Day')\n",
    "        ax2.set_title('Daily Upload Frequency')\n",
    "        ax2.tick_params(axis='x', rotation=45)\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add burst detection\n",
    "        mean_daily = daily_counts.mean()\n",
    "        burst_days = daily_counts[daily_counts > mean_daily + daily_counts.std()]\n",
    "        if len(burst_days) > 0:\n",
    "            ax2.bar(burst_days.index, burst_days.values, alpha=0.9, color='red', \n",
    "                   label=f'Burst Days (> {mean_daily:.1f} + Ïƒ)')\n",
    "            ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Get top candidates for enhanced timeline analysis\n",
    "top_candidates = candidates.head(5)['user_id'].tolist()\n",
    "\n",
    "print(\"Creating enhanced timeline plots for top 5 journal runner candidates...\")\n",
    "\n",
    "for i, user_id in enumerate(top_candidates):\n",
    "    fig = plot_enhanced_user_timeline(user_id, records_df, users_df)\n",
    "    plt.savefig(f'figures/enhanced_timeline_user_{user_id}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"Enhanced timeline for user {user_id} saved to figures/enhanced_timeline_user_{user_id}.png\")\n",
    "    \n",
    "    # Show detailed user stats\n",
    "    user_stats = users_df[users_df['user_id'] == user_id].iloc[0]\n",
    "    print(f\"  ðŸ“Š User {user_id} Statistics:\")\n",
    "    print(f\"     â€¢ Records: {user_stats['n_records']}\")\n",
    "    print(f\"     â€¢ External DOI consistency: {user_stats['external_doi_consistency']:.3f}\")\n",
    "    print(f\"     â€¢ Repetitive author score: {user_stats['no_repetitive_author_score']:.3f}\")\n",
    "    print(f\"     â€¢ Author intersection ratio: {user_stats['author_intersection_ratio']:.3f}\")\n",
    "    print(f\"     â€¢ Upload burstiness: {user_stats['burstiness']:.3f}\")\n",
    "    print(f\"     â€¢ Spam records: {user_stats['spam_record_cnt']} ({user_stats['spam_record_ratio']:.1%})\")\n",
    "\n",
    "# ## 11. Feature Importance Analysis with Insights\n",
    "\n",
    "# Feature importance analysis helps us understand which behavioral indicators are most effective at distinguishing journal runners from normal users, guiding our detection criteria and helping us focus on the most predictive signals. This analysis reveals whether our engineered features like repetitive author scores and DOI consistency are actually capturing the patterns we expect to see in journal-running behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1f73c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a more comprehensive feature importance analysis\n",
    "print(\"Analyzing feature importance for journal runner detection...\")\n",
    "\n",
    "# Create binary target: is candidate or not\n",
    "users_df['is_candidate'] = users_df['user_id'].isin(candidates['user_id'])\n",
    "\n",
    "# Calculate multiple importance metrics\n",
    "feature_importance = {}\n",
    "for feature in numeric_features:\n",
    "    # Correlation with target\n",
    "    correlation = users_df[feature].corr(users_df['is_candidate'])\n",
    "    \n",
    "    # Mutual information (if available)\n",
    "    try:\n",
    "        from sklearn.feature_selection import mutual_info_classif\n",
    "        mi_score = mutual_info_classif(users_df[[feature]], users_df['is_candidate'], random_state=42)[0]\n",
    "    except:\n",
    "        mi_score = np.nan\n",
    "    \n",
    "    # Effect size (Cohen's d)\n",
    "    candidate_values = users_df[users_df['is_candidate']][feature].dropna()\n",
    "    non_candidate_values = users_df[~users_df['is_candidate']][feature].dropna()\n",
    "    \n",
    "    if len(candidate_values) > 0 and len(non_candidate_values) > 0:\n",
    "        pooled_std = np.sqrt(((len(candidate_values) - 1) * candidate_values.var() + \n",
    "                             (len(non_candidate_values) - 1) * non_candidate_values.var()) / \n",
    "                            (len(candidate_values) + len(non_candidate_values) - 2))\n",
    "        cohens_d = (candidate_values.mean() - non_candidate_values.mean()) / pooled_std if pooled_std > 0 else 0\n",
    "    else:\n",
    "        cohens_d = 0\n",
    "    \n",
    "    feature_importance[feature] = {\n",
    "        'correlation': abs(correlation) if not np.isnan(correlation) else 0,\n",
    "        'mutual_info': mi_score if not np.isnan(mi_score) else 0,\n",
    "        'cohens_d': abs(cohens_d)\n",
    "    }\n",
    "\n",
    "# Create comprehensive importance plot\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# 1. Correlation importance\n",
    "corr_importance = [(feat, data['correlation']) for feat, data in feature_importance.items()]\n",
    "corr_importance.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "features, importance = zip(*corr_importance)\n",
    "bars1 = axes[0].bar(range(len(features)), importance, color='skyblue', alpha=0.7)\n",
    "axes[0].set_xlabel('Features')\n",
    "axes[0].set_ylabel('Absolute Correlation')\n",
    "axes[0].set_title('Feature Importance: Correlation with Candidate Status')\n",
    "axes[0].set_xticks(range(len(features)))\n",
    "axes[0].set_xticklabels(features, rotation=45, ha='right')\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels\n",
    "for bar, imp in zip(bars1, importance):\n",
    "    axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                 f'{imp:.3f}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# 2. Mutual information importance (if available)\n",
    "mi_importance = [(feat, data['mutual_info']) for feat, data in feature_importance.items() if data['mutual_info'] > 0]\n",
    "if mi_importance:\n",
    "    mi_importance.sort(key=lambda x: x[1], reverse=True)\n",
    "    features, importance = zip(*mi_importance)\n",
    "    bars2 = axes[1].bar(range(len(features)), importance, color='lightgreen', alpha=0.7)\n",
    "    axes[1].set_xlabel('Features')\n",
    "    axes[1].set_ylabel('Mutual Information')\n",
    "    axes[1].set_title('Feature Importance: Mutual Information')\n",
    "    axes[1].set_xticks(range(len(features)))\n",
    "    axes[1].set_xticklabels(features, rotation=45, ha='right')\n",
    "    axes[1].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    for bar, imp in zip(bars2, importance):\n",
    "        axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001, \n",
    "                     f'{imp:.3f}', ha='center', va='bottom', fontsize=8)\n",
    "else:\n",
    "    axes[1].text(0.5, 0.5, 'Mutual Information\\nNot Available', ha='center', va='center', \n",
    "                 transform=axes[1].transAxes, fontsize=12)\n",
    "    axes[1].set_title('Feature Importance: Mutual Information')\n",
    "\n",
    "# 3. Effect size importance\n",
    "effect_importance = [(feat, data['cohens_d']) for feat, data in feature_importance.items()]\n",
    "effect_importance.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "features, importance = zip(*effect_importance)\n",
    "bars3 = axes[2].bar(range(len(features)), importance, color='orange', alpha=0.7)\n",
    "axes[2].set_xlabel('Features')\n",
    "axes[2].set_ylabel(\"Cohen's d (Effect Size)\")\n",
    "axes[2].set_title('Feature Importance: Effect Size')\n",
    "axes[2].set_xticks(range(len(features)))\n",
    "axes[2].set_xticklabels(features, rotation=45, ha='right')\n",
    "axes[2].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add effect size interpretation\n",
    "for i, (bar, imp) in enumerate(zip(bars3, importance)):\n",
    "    axes[2].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                 f'{imp:.3f}', ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "    # Color code by effect size\n",
    "    if imp > 0.8:\n",
    "        bar.set_color('red')\n",
    "    elif imp > 0.5:\n",
    "        bar.set_color('orange')\n",
    "    elif imp > 0.2:\n",
    "        bar.set_color('yellow')\n",
    "    else:\n",
    "        bar.set_color('lightblue')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/comprehensive_feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Comprehensive feature importance analysis saved to figures/comprehensive_feature_importance.png\")\n",
    "\n",
    "# Print feature importance summary\n",
    "print(\"\\nðŸ“Š FEATURE IMPORTANCE SUMMARY:\")\n",
    "print(\"Feature | Correlation | Effect Size | Interpretation\")\n",
    "print(\"-\" * 60)\n",
    "for feature in features:\n",
    "    corr = feature_importance[feature]['correlation']\n",
    "    effect = feature_importance[feature]['cohens_d']\n",
    "    \n",
    "    if effect > 0.8:\n",
    "        interpretation = \"Very Strong Effect\"\n",
    "    elif effect > 0.5:\n",
    "        interpretation = \"Strong Effect\"\n",
    "    elif effect > 0.2:\n",
    "        interpretation = \"Moderate Effect\"\n",
    "    else:\n",
    "        interpretation = \"Weak Effect\"\n",
    "    \n",
    "    print(f\"{feature:20} | {corr:10.3f} | {effect:10.3f} | {interpretation}\")\n",
    "\n",
    "# ## 12. Summary Statistics and Insights\n",
    "\n",
    "# Comprehensive summary statistics provide a complete picture of our detection results, helping us understand the scale of journal-running activity on Zenodo and validate our detection approach. These insights help us assess whether our thresholds are reasonable and whether we're capturing the right behavioral patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f798904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary statistics\n",
    "print(\"=\" * 60)\n",
    "print(\"ZENODO JOURNAL RUNNER DETECTION - SUMMARY REPORT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "total_users = len(users_df)\n",
    "users_with_50_plus = len(users_df[users_df['n_records'] >= 50])\n",
    "candidate_count = len(candidates)\n",
    "\n",
    "print(f\"\\nðŸ“Š DATASET OVERVIEW:\")\n",
    "print(f\"   â€¢ Total users analyzed: {total_users:,}\")\n",
    "print(f\"   â€¢ Users with â‰¥50 records: {users_with_50_plus:,} ({users_with_50_plus/total_users*100:.1f}%)\")\n",
    "print(f\"   â€¢ Journal runner candidates: {candidate_count:,} ({candidate_count/users_with_50_plus*100:.1f}% of high-volume users)\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ DETECTION CRITERIA APPLIED:\")\n",
    "print(f\"   â€¢ Minimum records: {CONFIG['min_records_threshold']}\")\n",
    "print(f\"   â€¢ External DOI consistency threshold: {CONFIG['external_doi_consistency_threshold']}\")\n",
    "print(f\"   â€¢ Max external prefixes: {CONFIG['max_external_prefixes']}\")\n",
    "print(f\"   â€¢ Min upload regularity: {CONFIG['min_upload_regularity']}\")\n",
    "print(f\"   â€¢ Max spam ratio: {CONFIG['max_spam_ratio']}\")\n",
    "print(f\"   â€¢ Min repetitive author score: {CONFIG['repetitive_author_threshold']}\")\n",
    "print(f\"   â€¢ Exclude safe communities: {CONFIG['safe_communities']}\")\n",
    "\n",
    "print(f\"\\nðŸ“ˆ CANDIDATE CHARACTERISTICS:\")\n",
    "if len(candidates) > 0:\n",
    "    print(f\"   â€¢ Average records per candidate: {candidates['n_records'].mean():.1f}\")\n",
    "    print(f\"   â€¢ Average External DOI consistency: {candidates['external_doi_consistency'].mean():.3f}\")\n",
    "    print(f\"   â€¢ Average repetitive author score: {candidates['no_repetitive_author_score'].mean():.3f}\")\n",
    "    print(f\"   â€¢ Average community dedication: {candidates['same_comm_ratio'].mean():.3f}\")\n",
    "    print(f\"   â€¢ Users with spam records: {len(candidates[candidates['spam_record_cnt'] > 0])} \"\n",
    "          f\"({len(candidates[candidates['spam_record_cnt'] > 0])/len(candidates)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nðŸ” KEY INSIGHTS:\")\n",
    "print(f\"   â€¢ {len(users_df[users_df['external_doi_consistency'] == 1.0]):,} users use exclusively external DOIs\")\n",
    "print(f\"   â€¢ {len(users_df[users_df['same_comm_ratio'] == 1.0]):,} users are dedicated to a single community\")\n",
    "print(f\"   â€¢ {len(users_df[users_df['spam_record_cnt'] > 0]):,} users have spam records associated\")\n",
    "print(f\"   â€¢ {len(users_df[users_df['has_safe_community']]):,} users have safe communities (independent users)\")\n",
    "print(f\"   â€¢ {len(users_df[users_df['no_repetitive_author_score'] >= 0.5]):,} users have high repetitive author scores (â‰¥0.5)\")\n",
    "\n",
    "print(f\"\\nðŸ’¾ OUTPUT FILES GENERATED:\")\n",
    "print(f\"   â€¢ data/records.parquet - Processed record data\")\n",
    "print(f\"   â€¢ data/users.parquet - User-level features\")\n",
    "print(f\"   â€¢ data/journal_runner_candidates.csv - Candidate list\")\n",
    "print(f\"   â€¢ figures/ - Visualization plots\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(f\"ANALYSIS COMPLETE: Found {candidate_count} potential journal runners\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ## 13. Additional Analysis: Feature Importance\n",
    "\n",
    "# This additional feature importance analysis provides a focused view of which behavioral indicators are most predictive of journal-running behavior, helping us refine our detection criteria and understand the relative strength of different signals. Understanding feature importance helps us prioritize which patterns to focus on when developing more sophisticated detection algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8950cd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze feature importance for candidate detection\n",
    "print(\"Analyzing feature importance for journal runner detection...\")\n",
    "\n",
    "# Create binary target: is candidate or not\n",
    "users_df['is_candidate'] = users_df['user_id'].isin(candidates['user_id'])\n",
    "\n",
    "# Calculate feature importance using correlation with target\n",
    "feature_importance = {}\n",
    "for feature in numeric_features:\n",
    "    correlation = users_df[feature].corr(users_df['is_candidate'])\n",
    "    feature_importance[feature] = abs(correlation)\n",
    "\n",
    "# Sort by importance\n",
    "sorted_importance = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "features, importance = zip(*sorted_importance)\n",
    "bars = plt.bar(range(len(features)), importance, color='skyblue', alpha=0.7)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Absolute Correlation with Candidate Status')\n",
    "plt.title('Feature Importance for Journal Runner Detection')\n",
    "plt.xticks(range(len(features)), features, rotation=45, ha='right')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, imp in zip(bars, importance):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "             f'{imp:.3f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Feature importance plot saved to figures/feature_importance.png\")\n",
    "print(\"\\nFeature importance ranking:\")\n",
    "for feature, imp in sorted_importance:\n",
    "    print(f\"  {feature}: {imp:.3f}\") "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
